{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBK0PP1mdQV4"
      },
      "source": [
        "#Logistic Regression for Banknote Authentication\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrXAqIBOdYYm"
      },
      "source": [
        "##Objective:\n",
        "This assignment aims to assess your ability to apply binary logistic regression to a real-world dataset containing only continuous features. You will practice loading data, preparing it for modeling, training a logistic regression model, interpreting its results, evaluating its performance using accuracy, and drawing basic conclusions.\n",
        "\n",
        "##Scenario:\n",
        "Imagine you are working for a financial institution developing automated systems to detect counterfeit banknotes. Data has been collected from images of genuine and forged banknote-like specimens. Features were extracted from these images using Wavelet Transform tools, resulting in four continuous numerical measurements. The goal is to build a model that can predict whether a banknote is genuine or forged based on these image-derived features.\n",
        "\n",
        "##Dataset:\n",
        "Banknote Authentication Dataset\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqEuzuLFeR__"
      },
      "source": [
        "##Import Relevent Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVftvXgOeEf4"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tQfkb2NeW8h"
      },
      "source": [
        "##Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDgOvU3peyOy"
      },
      "source": [
        "###Task 1.1: Starter Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aDWti0UeOhf",
        "outputId": "e2c45828-3aac-4124-8886-bffc7218fcda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assignment starter code executed. Context Date: April 5, 2025\n",
            "\n",
            "--- Task 1: Data Loading and Preparation ---\n",
            "Data loaded successfully.\n",
            "\n",
            "DataFrame Head:\n",
            "   Variance  Skewness  Curtosis  Entropy  Class\n",
            "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
            "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
            "2   3.86600   -2.6383    1.9242  0.10645      0\n",
            "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
            "4   0.32924   -4.4552    4.5718 -0.98880      0\n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1372 entries, 0 to 1371\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   Variance  1372 non-null   float64\n",
            " 1   Skewness  1372 non-null   float64\n",
            " 2   Curtosis  1372 non-null   float64\n",
            " 3   Entropy   1372 non-null   float64\n",
            " 4   Class     1372 non-null   int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 53.7 KB\n",
            "\n",
            "DataFrame Description:\n",
            "          Variance     Skewness     Curtosis      Entropy        Class\n",
            "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
            "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
            "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
            "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
            "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
            "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
            "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
            "max       6.824800    12.951600    17.927400     2.449500     1.000000\n"
          ]
        }
      ],
      "source": [
        "# Starter Code for Assignment: Logistic Regression for Banknote Authentication\n",
        "\n",
        "# Suppress potential convergence warnings for cleaner output (optional)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# --- Reference Date ---\n",
        "# Assignment context date: Saturday, April 5, 2025 (as per environment context)\n",
        "print(f\"Assignment starter code executed. Context Date: April 5, 2025\")\n",
        "\n",
        "# --- Task 1: Data Loading and Preparation ---\n",
        "print(\"\\n--- Task 1: Data Loading and Preparation ---\")\n",
        "\n",
        "# URL for the dataset\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt'\n",
        "\n",
        "# Define column names\n",
        "column_names = ['Variance', 'Skewness', 'Curtosis', 'Entropy', 'Class']\n",
        "\n",
        "# Load data, specifying no header and comma separator\n",
        "try:\n",
        "    df = pd.read_csv(url, header=None, names=column_names, sep=',')\n",
        "    print(\"Data loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {e}\")\n",
        "    # Exit or handle error appropriately in a real script\n",
        "    exit()\n",
        "# Display basic info - Verify data loaded correctly\n",
        "print(\"\\nDataFrame Head:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataFrame Info:\")\n",
        "df.info()\n",
        "print(\"\\nDataFrame Description:\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hm5XhRBf12q"
      },
      "source": [
        "###Task 1.2: Data Loading and Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJtNifLff3ls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48e0f8f4-a8ac-44db-d47e-ca7c7bcd92f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Described:           Variance     Skewness     Curtosis      Entropy\n",
            "count  1372.000000  1372.000000  1372.000000  1372.000000\n",
            "mean      0.433735     1.922353     1.397627    -1.191657\n",
            "std       2.842763     5.869047     4.310030     2.101013\n",
            "min      -7.042100   -13.773100    -5.286100    -8.548200\n",
            "25%      -1.773000    -1.708200    -1.574975    -2.413450\n",
            "50%       0.496180     2.319650     0.616630    -0.586650\n",
            "75%       2.821475     6.814625     3.179250     0.394810\n",
            "max       6.824800    12.951600    17.927400     2.449500\n",
            "Y Described: count    1372.000000\n",
            "mean        0.444606\n",
            "std         0.497103\n",
            "min         0.000000\n",
            "25%         0.000000\n",
            "50%         0.000000\n",
            "75%         1.000000\n",
            "max         1.000000\n",
            "Name: Class, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# 1. Define the feature matrix X\n",
        "X_auth = df[['Variance', 'Skewness', 'Curtosis', 'Entropy']]\n",
        "\n",
        "# 2. Define the target vector y\n",
        "y_auth = df['Class']\n",
        "\n",
        "# 3. Describe the data\n",
        "print('X Described:',X_auth.describe())\n",
        "print('Y Described:',y_auth.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouI-2_ZierTk"
      },
      "source": [
        "###Task 2: Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLLpXTxvesgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bbfb791-3867-4ed9-d50f-40c9bbc76adf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Task 2: Train-Test Split ---\n",
            "X Train set size: 1097, X Test set size: 275\n",
            "Y Train set size: 1097, Y Test set size: 275\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Task 2: Train-Test Split ---\")\n",
        "# 1. Split X and y into training and testing sets\n",
        "X_auth_train, X_auth_test, y_auth_train, y_auth_test = train_test_split(\n",
        "    X_auth, y_auth,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=y_auth\n",
        "    )\n",
        "\n",
        "# 2. Print the shapes of the resulting arrays\n",
        "print(f\"X Train set size: {X_auth_train.shape[0]}, X Test set size: {X_auth_test.shape[0]}\")\n",
        "print(f\"Y Train set size: {y_auth_train.shape[0]}, Y Test set size: {y_auth_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRmQGgK3evP9"
      },
      "source": [
        "###Task 3: Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFPY0jq3ewKJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e812df-e35b-4400-ce1c-3f11dce39aee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Task 3: Model Training ---\n",
            "Model trained on banknote authentication data\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Task 3: Model Training ---\")\n",
        "# 1. Initialize a LogisticRegression model (with random_state=42)\n",
        "log_reg_auth = LogisticRegression(random_state=42)\n",
        "\n",
        "# 2. Train the model using X_train_scaled and y_train\n",
        "log_reg_auth.fit(X_auth_train, y_auth_train)\n",
        "\n",
        "print('Model trained on banknote authentication data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_67VhTle1cb"
      },
      "source": [
        "###Task 4: Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5g0cjtUe2iO",
        "outputId": "3b7dce15-90e7-4e1c-8a4d-bc4de3b5c061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Task 4: Model Evaluation ---\n",
            "Banknote Authentication Predictions (Test Set):\n",
            "Actual Pass/Fail:    [0 1 0 1 1]\n",
            "Predicted Pass/Fail: [0 1 0 1 1]\n",
            "Predicted Probability (Pass): [0.    0.996 0.107 0.994 1.   ]\n",
            "\n",
            "---Metrics---\n",
            "Accuracy:  0.9855\n",
            "Precision: 0.9683\n",
            "Recall:    1.0000\n",
            "F1-Score:  0.9839\n",
            "\n",
            "---Confusion Matrix---\n",
            "[[149   4]\n",
            " [  0 122]]\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Task 4: Model Evaluation ---\")\n",
        "# 1. Make predictions (y_pred) on the test data using the trained model\n",
        "y_auth_pred_labels = log_reg_auth.predict(X_auth_test)\n",
        "y_auth_pred_proba = log_reg_auth.predict_proba(X_auth_test)[:, 1]\n",
        "\n",
        "print(\"Banknote Authentication Predictions (Test Set):\")\n",
        "print(f\"Actual Pass/Fail:    {y_auth_test.iloc[:5].values}\")\n",
        "print(f\"Predicted Pass/Fail: {y_auth_pred_labels[:5]}\")\n",
        "print(f\"Predicted Probability (Pass): {y_auth_pred_proba[:5].round(3)}\")\n",
        "\n",
        "# 2. Calculate Accuracy\n",
        "accuracy_auth = accuracy_score(y_auth_test, y_auth_pred_labels)\n",
        "cm_auth = confusion_matrix(y_auth_test, y_auth_pred_labels)\n",
        "\n",
        "# 3. Calculate metrics, use zero_division=0 for robustness\n",
        "precision_auth = precision_score(y_auth_test, y_auth_pred_labels, zero_division=0)\n",
        "recall_auth = recall_score(y_auth_test, y_auth_pred_labels, zero_division=0)\n",
        "f1_auth = f1_score(y_auth_test, y_auth_pred_labels, zero_division=0)\n",
        "\n",
        "# Print Metrics\n",
        "print('\\n---Metrics---')\n",
        "print(f\"Accuracy:  {accuracy_auth:.4f}\")\n",
        "print(f\"Precision: {precision_auth:.4f}\")\n",
        "print(f\"Recall:    {recall_auth:.4f}\")\n",
        "print(f\"F1-Score:  {f1_auth:.4f}\")\n",
        "\n",
        "print('\\n---Confusion Matrix---')\n",
        "print(cm_auth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ8v7WgUe5-A"
      },
      "source": [
        "###Task 5: Coefficient Interpretation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcbxnrPme5d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dab4911-622b-4124-bade-3c8f96d4cfde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Task 5: Coefficient Interpretation ---\n",
            "\n",
            "Model Intercept: 3.7438\n",
            "Coefficient for Skewness: -1.7832\n",
            "Coefficient for Entropy: -0.0901\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Task 5: Coefficient Interpretation ---\")\n",
        "# 1. Extract coefficients from the trained model\n",
        "\n",
        "#get intercept and coefficients\n",
        "intercept_auth = log_reg_auth.intercept_[0]\n",
        "coefs = log_reg_auth.coef_[0]\n",
        "\n",
        "#convert features into columns\n",
        "feature_names = X_auth_train.columns\n",
        "\n",
        "#convert columns into dataframe\n",
        "coeffs_log_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefs})\n",
        "\n",
        "# 2. Print the coefficients for 'Skewness' and 'Entropy'\n",
        "print(f\"\\nModel Intercept: {intercept_auth:.4f}\") #prints intercept for the whole model\n",
        "print(f\"Coefficient for Skewness: {coeffs_log_df.loc[1, 'Coefficient']:.4f}\") #skewness\n",
        "print(f\"Coefficient for Entropy: {coeffs_log_df.loc[3, 'Coefficient']:.4f}\") #entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7TVm3KIe-mN"
      },
      "source": [
        "###Task 6: Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-GVQfrYe-AI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f4ac82-7de8-4b46-c5ee-8d687497fba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Task 6: Interpretation ---\n",
            "The model is has a 98% accuracy score in predicting a genuine banknote over a forged one.\n",
            "Precision tells us that the predicted genuine banknote is 96%, while Recall found that all of the genuine banknotes were found by the model.\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Task 6: Interpretation ---\")\n",
        "# 1. Write 1-2 print statements summarizing your findings (accuracy, interpretation highlights, model utility)\n",
        "\n",
        "print('The model is has a 98% accuracy score in predicting a genuine banknote over a forged one.\\nPrecision tells us that the predicted genuine banknote is 96%, while Recall found that all of the genuine banknotes were found by the model.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2k6JLMffFJp"
      },
      "source": [
        "###Task 7: Code Quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a_XbKwVfGLx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce82adcd-9893-40c1-cc3d-1dc319c072d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Task 7: Code Quality ---\n",
            "Code is commented, uses meaningful variable names, and runs without errors.\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Task 7: Code Quality ---\")\n",
        "#no code necessary\n",
        "print(\"Code is commented, uses meaningful variable names, and runs without errors.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}